* Sock Option in TCP/UDP packet
sock program usage in unpv12e source code folder 
[admin1@TeamCI-136 sock]$ ./sock
usage: sock [ options ] <host> <port>              (for client; default)
       sock [ options ] -s [ <IPaddr> ] <port>     (for server)
       sock [ options ] -i <host> <port>           (for "source" client)
       sock [ options ] -i -s [ <IPaddr> ] <port>  (for "sink" server)
       sink, source means no input need to transmit
options: -b n  bind n as client's local port number
         -c    convert newline to CR/LF & vice versa
         -f a.b.c.d.p  foreign IP address = a.b.c.d, foreign port # = p
         -g a.b.c.d  loose source route
         -h    issue TCP half close on standard input EOF
         -i    "source" data to socket, "sink" data from socket (w/-s)
         -j a.b.c.d  join multicast group
         -k    write or writev in chunks
         -l a.b.c.d.p  client's local IP address = a.b.c.d, local port # = p
         -n n  # buffers to write for "source" client (default 1024)
         -o    do NOT connect UDP client
         -p n  # ms to pause before each read or write (source/sink)
         -q n  size of listen queue for TCP server (default 5)
         -r n  # bytes per read() for "sink" server (default 1024)
         -s    operate as server instead of client
         -t n  set multicast ttl
         -u    use UDP instead of TCP
         -v    verbose
         -w n  # bytes per write() for "source" client (default 1024)
         -x n  # ms for SO_RCVTIMEO (receive timeout)
         -y n  # ms for SO_SNDTIMEO (send timeout)
         -A    SO_REUSEADDR option
         -B    SO_BROADCAST option
         -C    set terminal to cbreak mode
         -D    SO_DEBUG option
         -E    IP_RECVDSTADDR option
         -F    fork after connection accepted (TCP concurrent server)
         -G a.b.c.d  strict source route
         -H n  IP_TOS option (16=min del, 8=max thru, 4=max rel, 2=min$)
         -I    SIGIO signal
         -J n  IP_TTL option
         -K    SO_KEEPALIVE option
         -L n  SO_LINGER option, n = linger time
         -N    TCP_NODELAY option
         -O n  # ms to pause after listen, but before first accept
         -P n  # ms to pause before first read or write (source/sink)
         -Q n  # ms to pause after receiving FIN, but before close
         -R n  SO_RCVBUF option
         -S n  SO_SNDBUF option
         -U n  enter urgent mode before write number n (source only)
         -V    use writev() instead of write(); enables -k too
         -W    ignore write errors for sink client
         -X n  TCP_MAXSEG option (set MSS)
         -Y    SO_DONTROUTE option
         -Z    MSG_PEEK



** sock options could be set  

/*    When  manipulating  socket options the level at which the option resides and the name of the option must be specified.  To manipulate options at the socket level, level is
      specified  as SOL_SOCKET.  To manipulate options at any other level the protocol number of the appropriate protocol controlling the option is supplied.  For example,  to
       indicate that an option is to be interpreted by the TCP protocol, level should be set to the protocol number of TCP; see getprotoent(3).*/

***  SO_LINGER (-L)
 "linger on close" socket option, when set it to 0, this cause the abort/RST(RESET) to be sent when connection closed not sending FIN as normal.
 -L n  SO_LINGER option, n = linger time

*** SO_REUSEADDR (-A)
./sock -b45198 127.0.0.1 6666  //client tcp port binding  to 45198 connected ot server port 6666
bind() error: Address already in use
in this case, the client will be in CLOSE_WAIT for client end the connection firsly, by using ctrl+c.  So if you start the client using the same port which it used before, there will be error.

SO_REUSEADDR opiton can make the address available if start the server using the 
sun % sock -v -s  -A 6666
there will be no "can't bind local address: Address already in use", and the server work well

**** SO_REUSEPORT for UDP packet
sun % sock -u-s-A 9999 so we try -A flag this time
can't bind local address: Address already in use
On systems that support multicasting (Chapter 12), this changes. Multiple end points can use the same local IP address and UDP port number, although the application normally must tell the
API that this is OK (i.e., our -A flag to specify the SO_REUSEADDR socket option).  4.4BSD, which supports multicasting, requires the application to set a different socket option
(SO_REUSEPORT) to allow multiple end points to share the same port. Furthermore each end point must specify this option, including the first one to use the port.
When a UDP datagram arrives whose destination IP address is a broadcast or multicast address, and there are multiple end points at the destination IP address and port number, one copy of the
incoming datagram is passed to each end point. (The end point's local IP address can be the wildcard, which matches any destination IP address.) But if a UDP datagram arrives whose
destination IP address is a unicast address, only a single copy of the datagram is delivered toone of the end points. Which end point gets the unicast datagram is implementation dependent.

***  SO_KEEPALIVE
we can start a client process that establishes a TCP connection with a server, and walk away for hours, days, weeks or months, and the connection remains up. Intermediate
routers can crash and reboot, phone lines may go down and back up, but as long as neither host at the ends of the connection reboots, the connection remains established.

The keepalive option is a timer to probe the peer of the connection is available when no data whantsoever transmitted in a tcp connection.
Many versions of the Telnet server and Rlogin server enable the keepalive option by default. This is why when you ssh a server, and no input for 2 hours, the connections will be shutdown.

In case of the intermediate router has crashed and is rebooting, TCP will think that the client's host has crashed, which is not what was happened, if the keepalvie probe.

client % sock -K 10.121.122.36 7788
-K for keepalive option
hello
recv error: Connection timed out
--------------------------
[root@localhost test]# tcpdump -i eth0 -p tcp and -p ip host 10.121.122.36
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes
10:45:02.998114 IP 10.121.122.12.32946 > 10.121.122.36.7788: P 1655330013:1655330042(29) ack 156085353 win 92 <nop,nop,timestamp 88357775 463165604>
10:45:02.998689 IP 10.121.122.36.7788 > 10.121.122.12.32946: . ack 29 win 1448 <nop,nop,timestamp 463969380 88357775>
10:45:04.917533 IP 10.121.122.12.32946 > 10.121.122.36.7788: P 29:30(1) ack 1 win 92 <nop,nop,timestamp 88359695 463969380>
10:45:04.918156 IP 10.121.122.36.7788 > 10.121.122.12.32946: . ack 30 win 1448 <nop,nop,timestamp 463971422 88359695>
12:45:04.918284 IP 10.121.122.12.32946 > 10.121.122.36.7788: . ack 1 win 92 <nop,nop,timestamp 95559696 463971422>
12:45:04.939589 IP 10.121.122.36.7788 > 10.121.122.12.32946: . ack 30 win 1448 <nop,nop,timestamp 471568065 88359695>
//when server's ethernet cable was unpluged, after 2 hours
14:45:04.939287 IP 10.121.122.12.32946 > 10.121.122.36.7788: . ack 1 win 92 <nop,nop,timestamp 102759717 471568065>
//no response from the server, that means server is down
-----------------------------------------------------------------


server % sock -s 7788
------------------------
10:48:32.842121 IP 10.121.122.12.32946 > 10.121.122.36.7788: P 33:34(1) ack 1 win 92 <nop,nop,timestamp 88359695 463969380>
10:48:32.842163 IP 10.121.122.36.7788 > 10.121.122.12.32946: . ack 34 win 1448 <nop,nop,timestamp 463971422 88359695>


12:55:08.330758 IP 10.121.122.12.32946 > 10.121.122.36.7788: . ack 1 win 92 <nop,nop,timestamp 95559696 463971422>
12:55:08.330912 IP 10.121.122.36.7788 > 10.121.122.12.32946: . ack 34 win 1448 <nop,nop,timestamp 471568065 88359695>
------------------------------

client will send a probe message firstly, in 12:55/45, ack message sent,if no echo message
client will actively close the connection.
 which socket is set keep_alive option, which will send the probe message.

If start a server like sock -s -K 7788,
then the server will send a probe message firstly, if no echo, then the server will actively close the connection.




*** SO_SNDBUF
these two buffers means the buffer which is for receiving data and sending data, why?
every tcp has a receive buffer in kernel, it won't overflow.
For tcp will inform peer the size of it's receive buffer, if the peer ignore this,  a packet containing more than that, this packet will be discard. 
If you want to specify the  tcp's receive buffer size, SO_REVBUF is that. 

---------------------------------------------------
Here it is the bug that the result is 2* parameter set. 


[liguo@localhost sock]$ ./sock -s 5555 -S 8192
sndbuflen = 8192, SO_SNDBUF = 16384
function   ssize_t send(int s, const void *buf, size_t len, int flags);
When prgm using send function to send data, tcp in kernel will copy the data from prg buffer to its
buffer which is SO_SNDBUF, and if the data is bigger than SO_SNDBUF, the prg will goto sleep until all data be copied form pfg buffer to this buffer.
So send() function return means the data has been copied into tcp's kernel buffer, not have been sent to the peer successfully.

they will be stored in this buffer?
When will these data be sent? 
1. if the data has made the buffer full
2. the data has been stored in the buffer for too much time
either one of the condition meet, the data in buffer will be wrapped into one tcp/ip packet 
and be sent really into the network
In this case 
1. a tcp packet may include two application layer messages,
if these two messages are sent without a time gap and these two message were short enough to
fit in one tcp packet.

2. a tcp packet maybe a part of one application layer message
if the application layer message is too long, it could be hold in the buffer of a tcp layer,
(send(,,size,), but it couldn't be sent into one tcp message, because a tcp packet will have
a limitation for two specific endpoints, that's the MSS(maximum send segment)
why? because the lower layer of tcp is erhenet, MTU is the limit for every erthenet packet,
ip packet will have a limit, thus tcp packet have a limit, this is MSS.
When two endpoints connection through loop interface, the MTU is bigger than ethernet.
--------
[liguo@butter sock]$ netstat -i
Kernel Interface table
Iface       MTU Met    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0       1500   0    55060      0      0      0      833      0      0      0 BMRU
lo        16436  
-------------------------------------------
[liguo@butter sock]$ ./sock -v 127.0.0.1 5555
connected on 10.121.122.66.32795 to 10.121.122.66.5555
TCP_MAXSEG = 16383

[guolili@cougar sock]$ ./sock -v butter 5555
connected on 10.121.122.66.32795 to 10.121.122.66.5555
TCP_MAXSEG = 1448


in socket API function send(socket, send_buf, buf_len,0)
send_buf in application layer should be less than the SO_SNDBUF in tcp layer

So what is the maximum size of a tcp packet depends on three:
1. SO_SNDBUF  the buffer size, the whole space to hold the data in tcp layer
2. MSS, the connection of two end points, the maximum value of the interface's MTU( MTU limits the ethernet packet length, so ip packect will be fragmented to adapt this MUT size)
3. the SO_RCVBUF of the received data peer, it will affect the r_wnd feild in tcp packet header, and when send data, the send data peer won't send more than r_wnd it get from the
received dtat peer.

so a tcp packet has two limits: 
(1).tcp protocol itself will devide the messages in send buffer
(2).the tcp payload in ip packet, and ip packet will be devided into MTU limited size
In wiresharklog, you will get the whole ip packet which has been reassembled by wireshark

3. a tcp packet contain one application message

*** SO_RCVBUF

[liguo@localhost sock]$ ./sock -s 5555 -R 1024
rcvbuflen = 1024, SO_RCVBUF = 2048
SO_SNDBUF is the send buffer of the socket in bytes,
SO_RCVBUF is the receive buffer of the socket in bytes.
the receivd buffer in tcp layer is for storing the data from ip layer.
There are two parameters: size of the "buf",  and buf_len means when receive buf_len bytes, recvfrom function will return. 0 is flag.
option SO_RCVBUF is the size value of buf(-R parameter for sock prg), buf_len is another thing, in this case -r parameter for sock prg.
/*The receive buffer size is tied to TCP''s advertised window in SYN message*/

tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
when retval=recvfrom(socket_id,buf,buf_len,0) retrun?
1. when received some data, the buffer space is engough but tiemout 
2. when rev buffer is almost full


what data will a revfrom get?
1.data is two sperated upper layer message
So upper layer invoing retval=revfrom(socket_id, buf, buf_len,0 ) buf_len is the size of buf, means the maximum data get from tcp layer to upper layer
one time from revfrom may get two upper layer mesage
2. data is part of a uppper layer message 

so application layer have it's own protocl, it can send length of a message, so revfrom could piece the framented data together. Though tcp layer could reassemble a upper layer
data, but it wont' guarantee one revfrom is one peer upper layer message, it will guaranteen the stream order. So if you received it for many times, you can piece them together by 
the header of the upper layer. usually the length.
Firsly received a data, get header to get length, then count the bytes received until it is 
equal to the length of the header, means a whole packet. 
because the revfrom function  will be effected by many factors, by the rev buffer and data arrive timing.

**** So tcp layer is ensuring the order of the received bytes, but not form once revfrom.
So when using tcp for transportation layer, the upper layer protocol is needed, at least
the lenghh field should be pre to the real data.

tpkt header is for this purpose:
TCP manages a continuous stream of octects, with no explicit bundaries.
So what if two upper layer messages in one tcp pkt?(how the receivd peer could divide these two)
what if a part of upper layer messages in one tcp pkt?(means the following-up packets is part of
this upper layer messages too)
ehenet header|ip header|tcp header|tpkt header|real data-0|
ehenet header|ip header|tcp header|real data-1|
if two packets are for only one upper layer message, the packet will be like above
How to asseble it in upper layer of tcp?
get the tpkt header, it will contian the whole lengthof this message, rev until get all the length
data in continuous packts.
Cause tcp is continuous stream, though in ip layer, the packet may not in order, via different
routes, but when ip layer delivered to tcp layer, they are continuous stream in order.
How?  tcp has the sequence nunber for them.

***** tpkt header format
   |---------+----------+---------------+------|
   | version | reserved | packet length | TPDU |
   |---------+----------+---------------+------|
   <8 bits>   <8 bits>   <  16 bits    > < variable length >
but there is a limitation, length is 16 bits, maximum is 65535, what if one upper layer message
if large than that?
So for tcp it is not the best protocol for messages(which has a bundaries) transport, sctp is a better choice.

***** sctp support for the message transfer
sctp support two bunddled messages, but each one has their individual chunk headers


** tcp offload engine
TCP offload engine or TOE is a technology used in network interface cards (NIC) to offload processing of the entire TCP/IP stack to the network controller. 
==============
> # ethtool -k eth0
> Offload parameters for eth0:
> rx-checksumming: off
> tx-checksumming: off
> scatter-gather: off
> tcp segmentation offload: off
> udp fragmentation offload: off
> generic segmentation offload: on
> 
> Wow.  I turned gso off and now it works just like before.
> No packets over size of mtu anymore, either.
> 
> State       Recv-Q Send-Q               Local Address:Port                 Peer Address:Port
> ESTAB      0       122334               80.223.84.180:57694                74.54.226.166:80     timer:(on,4.475ms,0) uid:518 ino:4546485 sk:2ea3ac80ffff8800


set MTU size with ifconfig command
ifconfig eth0 mtu 1024 up
in redhat
vim /etc/sysconfig/network-scripts/ifcfg-eth0
MTU-="9000"
# service network restart

why tcp pakcet length captured in wireshark is larger than MTU
The MSS is what the TCP stack will use to segment data before it is being send out the network interface. However, libpcap captures the packets between the TCP stack and the
NIC driver. In modern NICs, some functions of the TCP/IP stack can be offloaded to the NIC, saving CPU cycles on the system. One of the offloaded features is TCP segmentation.

So you see the large segment being sent to the NIC and the NIC will segment it into packets that will fit the MTU of the network.

You can verify this by making the trace on both sides, only on the sending side you will see the large packets
[guolili@cougar test]$ ethtool -k eth0
Offload parameters for eth0:
rx-checksumming: on
tx-checksumming: on
scatter-gather: on
tcp segmentation offload: on
[guolili@cougar test]$ sudo ethtool -K eth0 tso off
Password:
[guolili@cougar test]$ ethtool -k eth0
Offload parameters for eth0:
rx-checksumming: on
tx-checksumming: on
scatter-gather: on
tcp segmentation offload: off
---------------------
===================
*** tcp parameter
$ /proc/sys/net/core/netdev_max_backlog
进入包的最大设备队列.默认是300,对重负载服务器而言,该值太低,可调整到1000.
$ /proc/sys/net/core/somaxconn
listen()的默认参数,挂起请求的最大数量.默认是128.对繁忙的服务器,增加该值有助于网络性能.可调整到256.
$ /proc/sys/net/core/optmem_max
socket buffer的最大初始化值,默认10K.
$ /proc/sys/net/ipv4/tcp_max_syn_backlog
进入SYN包的最大请求队列.默认1024.对重负载服务器,增加该值显然有好处.可调整到2048.
$ /proc/sys/net/ipv4/tcp_retries2
TCP失败重传次数,默认值15,意味着重传15次才彻底放弃.可减少到5,以尽早释放内核资源.
$ /proc/sys/net/ipv4/tcp_keepalive_time
$ /proc/sys/net/ipv4/tcp_keepalive_intvl
$ /proc/sys/net/ipv4/tcp_keepalive_probes
这3个参数与TCP KeepAlive有关.默认值是:
tcp_keepalive_time = 7200 seconds (2 hours)
tcp_keepalive_probes = 9
tcp_keepalive_intvl = 75 seconds
意思是如果某个TCP连接在idle 2个小时后,内核才发起probe.如果probe 9次(每次75秒)不成功,内核才彻底放弃,认为该连接已失效.对服务器而言,显然上述值太大. 可调整到:
/proc/sys/net/ipv4/tcp_keepalive_time 1800
/proc/sys/net/ipv4/tcp_keepalive_intvl 30
/proc/sys/net/ipv4/tcp_keepalive_probes 3
$ proc/sys/net/ipv4/ip_local_port_range
指定端口范围的一个配置,默认是32768 61000,已够大.
 
net.ipv4.tcp_syncookies = 1
表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1
表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1
表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_fin_timeout = 30
表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。
net.ipv4.tcp_keepalive_time = 1200
表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。
net.ipv4.ip_local_port_range = 1024 65000
表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
net.ipv4.tcp_max_syn_backlog = 8192
表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
net.ipv4.tcp_max_tw_buckets = 5000
表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为 5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。



=======================
-------------------------
*** tcp buffer
Optimizing Linux network TCP/IP kernel parameters

$ /proc/sys/net/ipv4/tcp_wmem   min    default    max
TCP写buffer,可参考的优化值:     8192   436600    873200
$ /proc/sys/net/ipv4/tcp_rmem
TCP读buffer,可参考的优化值: 32768 436600 873200
$ /proc/sys/net/ipv4/tcp_mem
同样有3个值,意思是:
net.ipv4.tcp_mem[0]:低于此值,TCP没有内存压力.
net.ipv4.tcp_mem[1]:在此值下,进入内存压力阶段.
net.ipv4.tcp_mem[2]:高于此值,TCP拒绝分配socket.
上述内存单位是页,而不是字节.可参考的优化值是:786432 1048576 1572864
Many Oracle professionals do not note the required setting for optimizing Oracle*Net on Oracle 10g release 2.  Here is a review of the suggested TCP/IP buffer parameters:

You can verify the Linux networking kernel parms from the root user with these commands::
4096 87380 8388608

/proc/sys/net/ipv4/tcp_rmem


4096 65536 8388608

/proc/sys/net/ipv4/tcp_wmem


4096 4096 4096

/proc/sys/net/ipv4/tcp_mem


Setting /etc/sysctl.conf

You can enter them in sysctl.conf in /etc to have them persist through shutdowns. For setting the live values use sysctl –w  from the root user.

$ sysctl –w net.core.rmem_default=262144  <== no spaces

For multiple value entries:

$ sysctl –w net.ipv4.tcp_rmem="4096 87380 8388608”

In sysctl.conf:

net.core.rmem_default = 262144 <== has spaces

net.ipv4.tcp_rmem = 4096 87380 8388608



when we modify tcp_rmem default vaule to 4096, then the Win size in SYN is
1448, and the maximum value of the window can reach to is 4868, twice of the default value size.
If the window size is 1448, then the peer will send the tcp packet with data
less than 720 bytes, that's half value of the advitised window size.
42                                  202
./sock -i -s 5555                   ./sock -i -n1 -w8192 42 5555  
|cat/proc/sys/net/ipv4/tcp_rmem     | cat /proc/sys/net/ipv4/tcp_rmem
4096 4096 5000                       4096 87380 3530752
|                                   |
|/  SYN win= 4640                   |
-----------                         |
|\
|
|SYN, win=1448      \
|-------------------                |
|                   /               |  
...................
|                                   | 
|     /data=720 (this fragmention is from the tcp layer,not from NIC(MTU)|
|      --------------               |
      \
cause the peer rec window is small, so it won't send so large data
..............
|
|win(max)=4868,ack=8192       \
|------------------------------     |
                              /     | 

===============================
setting the receive buffer
[guolili@cougar test]$ cat /proc/sys/net/ipv4/tcp_rmem
4096    87380   3530752
//for 4096 is the minimum value in tcp_rmem, so -R option could only set 2048, 
then SO_RCVBUF==4096

cat [guolili@cougar test]$ cat ts.sh
  while read line
    do
      echo `date '+%T.%N'` $line
    done


./sock -i -s  -v  -R2048  -P4 -p2 -r256 7777 2>&1 |./ts.sh
11:02:56.389733546 SO_RCVBUF = 4096
11:03:09.983845150 connection on 10.121.122.202.7777 from 10.121.122.122.55566
11:03:09.992455346 SO_RCVBUF = 4096
11:03:09.993827882 TCP_MAXSEG = 1148
11:03:09.995618701 received 256 bytes
11:03:09.997066876 received 256 bytes
11:03:09.998543407 received 256 bytes
11:03:10.000741475 received 256 bytes
11:03:10.002205434 received 256 bytes

./sock -i 10.121.122.202  -n10
the window size in syn will be 2296 half of the actual recieve buffer size
window advertisament
len=1024   ->
len=1148   ->
win=256    <-
len=256, dseq=2173  ->
ack=2429, win =0     <-
seq=2428 len=0  (window probing) ->
ack=2429, win =0     <-
seq=2428 len=0  (window probing) ->
ack=2429, win =0     <-
seq=2428 len=0  (window probing) ->
......
win=1344    <-   until window size is 1344, it update the window size(for half of the buffer szie)
===============================
sock option
sock -u -v 10.121.122.99 6666
sock -u -s -v -E -R256 - P30 6666

limit the peer address
./sock -s -u -v -E -f 10.121.122.202.4444  10.121.122.97   6666
./sock -u -v -b 4444 10.121.222.97 6666
===================
ip packet reassemble
IP fragment
DF don't fragment
ip packet reasseble is in the next hop, so ip reasseble is trasparent to tcp/udp layer.
if not in order, ip packet could be reassemble also
udp 1473 (frag 26304: 1480@0+)   (frag id: datalen@offset+) + means more data is coming
udp (frag 26304:1@1480) no +this means the end of the fragment
so there are 1481 bytes, it be devided into two fragments



*** tcp packet reassemble
(1).tcp protocol itself will devide the messages in send buffer
for example
[guolili@cougar test]$ nc  10.121.122.12 4444 <out.dat
[guolili@cougar test]$ ll out.dat
-rw-rw-r--  1 guolili guolili 5120 May  4 14:01 out.dat
a 5k file, will be devided into three tcp packet only in tcp layer: 2896, 1448, 776

but in received side, tcp packet in tcp layer is:1448, 1448,1448
[gll@TTCN9 test]$ nc -l -p 4444 >aout
[gll@TTCN9 test]$ ll aout
-rw-rw-r--  1 gll gll 5120 May  4 14:03 aout

So in tcp layer, one send tcp data will be fragmented into different frames in send side and receive side,
cause ip is a stream oriented protocol, it won't guaranteen every send/receive will be the same data.
And in tcp header, just sequence number, no length field, so the upper layer of tcp will have the length
field to reassemble tcp streams into a complete packet.

(2).the tcp payload in ip packet, and ip packet will be devided into MTU limited size, means
ip packet will be reassembled by ip header lenghth field(16bit)
In wiresharklog, you will get the whole ip packet which has been reassembled by wireshark

*** udp packet reassemble
udp won't be fragmented in udp layer, but udp will reassemlbe the ip fragment into one udp packet by the 
length fields in udp layer
it will be framgmented in ip layer for MTU limits




** example of tcp transmission
[root@TeamCI-136 glili]# /usr/sbin/tcpdump -i lo |tee p.cap
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes
11:45:08.912572 IP localhost.localdomain.53623 > localhost.localdomain.7788: S 3524904661:3524904661(0) win 32792 <mss 16396,sackOK,timestamp 1202389692 0,nop,wscale 7>
//SYN, sequencenumber:sequencenumber, jwscale 7 means window scale will multiple 2**7=128 in the Pack packet, mss is MTU vaule
// win is advertised window
11:45:08.912801 IP localhost.localdomain.7788 > localhost.localdomain.53623: S 945307363:945307363(0) ack 3524904662 win 32768 <mss 16396,sackOK,timestamp 1202389692 1202389692,nop,wscale 7>
11:45:08.912824 IP localhost.localdomain.53623 > localhost.localdomain.7788: . ack 1 win 257 <nop,nop,timestamp 1202389692 1202389692>
//win 257 means 257*128=32896, this is similar to 32792 first win size. this win is th current receive window of host


11:45:08.912744 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 1:8193(8192) ack 1 win 257 <nop,nop,timestamp 1202389692 1202389692>
11:45:08.912755 IP localhost.localdomain.7788 > localhost.localdomain.53623: . ack 8193 win 386 <nop,nop,timestamp 1202389692 1202389692>
//ack number of received sequence number, and current window size, if there are two same ack number message with different win number
//that's a window size update message(Tcp window update) message,
11:45:08.912765 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 8193:16385(8192) ack 1 win 257 <nop,nop,timestamp 1202389692 1202389692>
11:45:08.912771 IP localhost.localdomain.7788 > localhost.localdomain.53623: . ack 16385 win 386 <nop,nop,timestamp 1202389692 1202389692>
11:45:08.912786 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 16385:24577(8192) ack 1 win 257 <nop,nop,timestamp 1202389693 1202389692>
11:45:08.912791 IP localhost.localdomain.7788 > localhost.localdomain.53623: . ack 24577 win 363 <nop,nop,timestamp 1202389693 1202389693>
11:45:08.912800 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 24577:32769(8192) ack 1 win 257 <nop,nop,timestamp 1202389693 1202389693>
11:45:08.912822 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 32769:49153(16384) ack 1 win 257 <nop,nop,timestamp 1202389693 1202389693>
//two write() message in one tcp segment since the send window is serverport 7788's receive window when SYN which is 32768, so 16384 is OK here
11:45:08.912827 IP localhost.localdomain.7788 > localhost.localdomain.53623: . ack 49153 win 264 <nop,nop,timestamp 1202389693 1202389693>
11:45:08.912836 IP localhost.localdomain.53623 > localhost.localdomain.7788: P 49153:57345(8192) ack 1 win 257 <nop,nop,timestamp 1202389693 1202389693>

==================================
[admin1@TeamCI-136 sock]$ ./sock -s -i  -v 7788 >/tmp/rere     // -i  "source" data to socket, "sink" data from socket (w/-s)
//in default, read() 1024 bytes 
received 1024 bytes
received 1024 bytes
received 1024 bytes
received 1024 bytes
......
====================================
[root@TeamCI-136 sock]# ./sock -v -i -w 8192 127.0.0.1 7788 <file.txt    // -i  "source" data to socket, "sink" data from socket (w/-s)
// indefault , write() 1024, b ut -w option specify 8192 bytes
wrote 8192 bytes
wrote 8192 bytes
wrote 8192 bytes
........
=============================
From above, we can see tcp packet is very different when in real NIC transmission(in tcpdump) and read, write function not always get teh same boundary but get same order stream.

